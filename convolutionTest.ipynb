{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "class callbacks(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>99.8):\n",
    "            print('Reached 99.8% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "path= f\"{getcwd()}/../../users/navne/downloads/mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_conv():\n",
    "    callback = callbacks()\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data(path=path)\n",
    "    training_images, test_images = training_images/255.0, test_images/255.0\n",
    "    training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "    test_images = test_images.reshape(10000,28,28,1)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation='relu', input_shape=(28,28,1)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128,activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        training_images,\n",
    "        training_labels,\n",
    "        epochs=20,\n",
    "        callbacks=[callback]\n",
    "    )\n",
    "    return history.epoch, history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.1389 - accuracy: 0.95811s - loss: 0.1413 -  - ETA: 1s - loss: 0.140 - ETA: 0s - loss: 0\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 50s 26ms/step - loss: 0.0482 - accuracy: 0.9853\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0293 - accuracy: 0.9907\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.0088 - accuracy: 0.99720s - loss: 0.0088 - accu\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 52s 28ms/step - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0049 - accuracy: 0.99820s - loss: 0.004\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0022 - accuracy: 0.9991\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0032 - accuracy: 0.9989\n"
     ]
    }
   ],
   "source": [
    "_,_ = train_mnist_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit9174c46b1a2d4c13aa081a6b0c594368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
